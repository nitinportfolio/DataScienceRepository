{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe14e631",
   "metadata": {},
   "source": [
    "## Discretisation plus Encoding\n",
    "\n",
    "What shall we do with the variable after discretisation? should we use the buckets as a numerical variable? or should we use the intervals as categorical variable?\n",
    "\n",
    "The answer is, you can do either.\n",
    "\n",
    "If you are building decision tree based algorithms and the output of the discretisation are integers (each integer referring to a bin), then you can use those directly, as decision trees will pick up non-linear relationships between the discretised variable and the target.\n",
    "\n",
    "If you are building linear models instead, the bins may not necessarily hold a linear relationship with the target. In this case, it may help improve model performance to treat the bins as categories and to one hot encoding, or target guided encodings like mean encoding, weight of evidence, or target guided ordinal encoding.\n",
    "\n",
    "We can easily do so by combining feature-engine's discretisers and encoders.\n",
    "\n",
    "## In this demo\n",
    "\n",
    "We will perform equal frequency discretisation followed by target guided orginal encoding using the titanic dataset\n",
    "\n",
    "If instead you would like to do weight of evidence or mean target encoding, you need only replace the Feature-engine's encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e8269a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
